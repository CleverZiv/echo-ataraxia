---
title: 后端研发避坑指南
tags:
  - Go
categories:
  - 总结
abbrlink: bf5703e6
date: 2023-01-08 00:00:00
---

> 后端研发在完成工作的过程中，“做对哪些事”决定了完成质量的上线，“做错哪些事”则决定了其下限。需要兼顾二者，甚至大多时候，“不做错”更重要
>
> 本文根据网上资料「如有侵权，请联系删除」以及笔者在工作中看到/遇到的 bad case 整理而成，持续更新...

<!-- more -->

# 一、架构设计层面

## 1.1 缓存设计

### 1.1.1 容易引发缓存穿透的设计

>缓存穿透是指当用户访问的数据，既不在缓存中，也不在数据库中，导致数据请求穿过缓存直接打到了数据库。而由于数据库中也没有要访问的数据，没办法构建缓存，这样后续的请求仍然会一直穿透到数据库

一般缓存会设计成如图：

<img src="https://typora-1258060977.cos.ap-beijing.myqcloud.com/img/image-20230108165038220.png" alt="image-20230108165038220" style="zoom:50%;" />

考虑有大量请求尝试获取并不在数据库中数据的情况，即会出现“缓存穿透”问题

#### 解决方案

方案1：缓存空值或默认值

当发现缓存穿透时，针对查询的数据在缓存中设置一个空值或默认值，避免后续同样的请求再次直接打到DB

方案2：使用布隆过滤器快速判断数据是否存在

> 布隆过滤器可以判断某个值是否一定不存在以及可能存在

具体做法：在写入数据库数据时，使用布隆过滤器做标记。用户请求到达时，业务线程确认缓存失效后，进一步通过查询布隆过滤器来判断数据是否存在。如果不存在，直接返回不用再请求DB

在分布式场景下，可以使用 redis 分布式布隆过滤器

### 1.1.2 热 key 失效引发缓存击穿

- 生成缓存 key 时要考虑业务场景是否会导致热key产生

    - 业务本身是否会有 热key，如果秒杀场景下的商品

    - 是否会生成默认key，导致极端场景下默认key转变为热key

      ```go
      const DefaultKey = "xxxx"
      func GenerateKey(param Param) string {
        key, err := param.GetConteng()
        if err != nil {
          return DefaultKey  // 可能会转变为热key
        }
        
        return key
      }
      ```

- 缓存失效时，回源数据（查询DB）要考虑下游保护

热key的缓存失效，第一个回源请求打到DB到重新构建缓存需要一段时间。在这段时间内仍然会接收到很多查询热key的请求，如果放任这些请求直接打到DB，则可能会打垮DB

#### 解决方案

问题1-热key问题：避免不要产生热key

1. 热key打散，不要使用单key，均匀分布到 redis 的不同分片中---事前避免
2. 接入相关组件，进行热key分析和防御---事中监控和防御

问题2-热key回源导致缓存击穿的问题

1. 多级缓存
2. 使用 redis 分布式锁，保证在回源时只有一个请求能打到DB---太重，影响性能
3. Singlefiight

### 1.1.3 大Key

> 大key会带来很高的延时，造成服务可用性下降

大key的标准：

1. string 类型的key，其 value 超过 10KB
2. hash/set/zset/list 数据结构中元素个数大于5000
3. hash/set/zset/list 数据结构中元素个数等于5000，但是每个元素大小达到1KB

#### 解决方案

1. 拆分大key
2. 对于 hash、set 这类结构，可以通过增加一层 hash 分桶来打散数据
3. 数据压缩

## 1.2 一致性设计

### 1.2.1 异步链路需要避免关键信息的不一致

在异步链路如消息、异步任务、异步推进接口等场景，实时获取时间、实时拉取在线配置，可能会导致前后的关键信息不一致，进而导致非预期的情况产生

> 关键信息的获取是否需要实时，需要根据具体业务逻辑决定。这里并不是说异步链路中就不能进行实时拉取信息的操作

#### 解决方案

1. 快照类的关键信息，应该在链路中透传（通过消息、接口参数等的方式）
2. 快照类的关键信息，持久化存储

### 1.2.2 批处理异常时要考虑子任务的状态

批处理要求子任务的处理结果与批处理结果一致，如果出现异常，需要记录每个子任务的状态并进行相应处理。不应该出现“批处理任务成功/失败，而存在子任务失败/成功”的情况

#### 解决方案

1. 事务/分布式事务
2. 记录子任务状态。出现异常时，支持子任务的 re_run

### 1.2.3 读写分离的一致性陷阱

读写分离后，对于弱一致性/最终一致性，会有主从延迟的情况。即写成功后不能立刻读到最新数据。典型的就是Mysql的主从模式（企业中一般使用的都是最终一致性）

#### 解决方案

1. 要充分调研清楚DB的“一致性”是强一致性还是弱一致性。如果是弱一致性，则在技术设计和编码时需要有“写立刻读会读不到数据”的预期，万不能有“写之后立刻就能读到数据”的预期
2. 弱一致性场景下需要写立刻读，评估该场景的QPS可使用直接读主（B端可以，C端一般不允许）
3. 采用组合方案从业务层实现读写的强一致性，如 redis+Mysql
4. 采用合适的中间件。有些中间件，可以实现对读写强一致性的自动处理，比如字节的 myredis

## 1.3 接口设计

### 1.3.1 不要信任上游请求参数

> 上游可能是前端、上游服务或者同一服务里的上游方法

1. 参数在业务层面非法，需要做校验
2. 有些参数会造成代码 panic，需要做校验以避免

### 1.3.2 接口IDL不能做不兼容的变更

不兼容的IDL变更包括：

- 修改字段id
- 修改字段类型
- 新增/删除 required 修饰的字段
- 修改方法名
- 变更字段名
- 变更字段默认值

建议的变更方式：

- 除非明确字段不会删除，否则最好不要使用 required 字段
- 任何新增的字段都是 optional 类型

# 二、代码设计层面

## 2.1 小细节

1. 获取某个对象的属性时，一定要先校验该对象是否为 nil
2. Switch 需要有 default 兜底，避免预期之外的场景逃逸

## 2.2 Json使用interface{}反序列化丢失精度

> 精度丢失：在不同类型数值A->B的转换过程中，如果A的表示范围与B不完全重合，A的范围>B。即存在某个数可以用A表示但是不可以用B表示，则在A->B转化的过程中会发生精度丢失

在使用包含 interface{} 的struct来做Json反序列化的时候，由于不知道[]byte的数值是具体的何种数值类型，会将数值全部转成float64类型，如果数值原本的数据类型的范围>float64，则可能发生精度丢失。golang 中原数值类型为 int64、uint64 在转化到 float64时会发生精度丢失

#### 解决方案

1. 数值采用 string 存储
2. 使用 decoder

具体实现可参考：https://www.51cto.com/article/697019.html

## 2.3 Loop 导致流量放大

循环逻辑中避免进行 rpc 等下游调用，很容易成为放大流量的杠杆；如果需要进行下游调用，重点关注次数是否过大（10倍以上放大）

#### 解决方案

1. 要求下游提供批处理接口
2. 循环内有并发调用，建议控制并发大小
3. 提供熔断机制，在极端情况下（明显延时、拒绝响应）触发熔断退出循环

## 2.4 Loop 中指针数据添加元素确保有效性（golang）

> 不能直接使用 for 循环中条件声明的变量

```go
s := make([]int64, 0)
s = append(s, 1)
s = append(s, 2)

s1 := make([]*int64, 0)
for _, v := range s {
  s1 = append(s1, &v)  // 错误，最后 s1 中的2个值会相同，都是s[1]的地址
}

// 正确的做法
for _, v := range s {
  tp := v
  s1 = append(s1, &tp)
}
```

# 三、持久层

## 3.1 数据库使用

### 3.1.1 Mysql 自增主键类型不一致

1. 与业务容量预期不一致：业务组件采用 `bigint`，但自增主键是`int`
2. 与代码定义的映射变量不一致：自增主键是`bigint`，但gorm的字段类型是`int32`
3. `unsigned`必须保证编程语言支持无符号类型，否则需要做适配（java 不支持）

### 3.1.2 数据库表设计不当导致服务可用性下降

- 表设计中，频繁使用外键约束：一般都不会使用外键约束，只是会把其它表的主键作为一个普通字段放在另一张表中
- 字段设计，随意设置类型
- 使用自增字段作为表的唯一键，应该使用自行生成的唯一键
- 对枚举字段使用字符串或者char类型
- Select 时习惯使用`*`
- 不适用 `limit` 限制返回的结果是胡良机
- 索引设计时，未遵循最左匹配原则

### 3.1.3 慢查询

# 四、锁的使用

## 4.1 锁未正确释放

场景1：

```go
func handler() error {
  l.RLock()
  conf, err := getConf()
  l.RUnLock()
  if err != nil {
    return err
  }
  // do something ..
}
```

问题在于`getConf()`可能panic，最终导致锁未释放

场景2：

```go
func handler() error {
  l.RLock()
  conf, err := getConf()
  defer l.RUnLock()
  if err != nil {
    return err
  }
  // do something ..
}
```

添加`defer`保证了锁一定会释放，没有问题。但是"do something"的耗时不确定，这会导致锁会占用过长时间。

#### 解决方案

将加锁的逻辑从整体业务逻辑中解耦出来。既保证锁安全释放，又保证锁能及时释放

```go
func handler() error{
  conf, err := getConfWithRLock()
  if err != nil{
    return err
  }
  // do something
}

func getConfWithRLock()(Conf, error) {
  l.RLock()
  defer func() {
    if r := recover(); r != nil {
      // do something for recover
    }
  }()
  defer l.RUnlock()
  conf, err := getConf()
  
  return conf, err
}
```

## 4.2 本地重复请求抑制不宜使用redis锁

上文聊到热key场景下，“第一次回源请求与构建缓存”两步时间差之间的重复请求会对下游造成很大压力。因此需要抑制这部分请求以保护下游

golang中比较好的做法是 singleflight，在抑制请求的同时又比较轻量级